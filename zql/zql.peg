#define DQUOTE \x22
#define SQUOTE \x27

#ifdef GO
{
    package zql
	import (
		"github.com/mccanne/zq/reglob"
		h "github.com/mccanne/zq/zql/helpers"
	)
}
#define RETURN(x) return x, nil
#define NULL nil
#define INIT_ASSIGN_VAR(x, var) x := var
#define ARRAY(...) []interface{}{__VA_ARGS__}
#define ARRAY_LEN(a) len(a.([]interface{}))
#define FOREACH(arr, var) for _, var := range arr
#define IF(stmt) if stmt
#define APPEND(arr, value) arr = append(arr, value)
#define PREPEND(value, arr) append([]interface{}{value}, (arr.([]interface{}))...)
#define TEXT string(c.text)
#define TOSTRING(s) fmt.Sprintf("%v", s)
#define ISNOTNULL(n) n != nil
#define ASSERT_ARRAY(a) a.([]interface{})
#define ASSERT_STRING(s) s.(string)
#define ASSERT_INT(i) i.(int)
#else
{
	const h = require("./helpers")
	const reglob = require("./reglob")
}
#define RETURN(x) return x
#define NULL null
#define INIT_ASSIGN_VAR(x, var) let x = var
#define ARRAY(...) [__VA_ARGS__]
#define ARRAY_LEN(a) a.length
#define FOREACH(arr, var) for(let var of arr)
#define IF(stmt) if (stmt)
#define APPEND(arr, value) arr.push(value)
#define PREPEND(value, arr) [value, ...arr]
#define TEXT text()
#define ASSERT_INT(i) i
#define TOSTRING(s) s.toString()
#define ISNOTNULL(n) (n)
#define ASSERT_ARRAY(a) a
#define ASSERT_STRING(s) s
#endif


start = _? ast:boomCommand _? EOF { RETURN(ast) }

boomCommand
  = procs:procChain {
      INIT_ASSIGN_VAR(filt, h.MakeFilterProc(h.MakeBooleanLiteral(true)))
      RETURN(h.MakeSequentialProc(PREPEND(filt, procs)))
    }
  / s:search _? rest:chainedProc* {
      if(ARRAY_LEN(rest) == 0) {
          RETURN(s)
      } else {
          RETURN(h.MakeSequentialProc(PREPEND(s, rest)))
      }
    }
  / s:search {
      RETURN(h.MakeSequentialProc(ARRAY(s)))
    }

procChain
  = first:proc rest:chainedProc* {
      IF(ISNOTNULL(rest)) {
        RETURN(PREPEND(first, rest))
      } else {
        RETURN(ARRAY(first))
      }
    }

chainedProc = _? "|" _? p:proc { RETURN(p) }

search
  = expr:searchExpr {
      RETURN(h.MakeFilterProc(expr))
    }

searchExpr
  = first:searchTerm rest:oredSearchTerm* {
      RETURN(h.MakeOrChain(first, rest))
    }

oredSearchTerm = _ orToken _ t:searchTerm { RETURN(t) }

searchTerm
  = first:searchFactor rest:andedSearchTerm* {
      RETURN(h.MakeAndChain(first, rest))
    }

andedSearchTerm = _ (andToken _)? f:searchFactor { RETURN(f) }

searchFactor
  = (notToken _ / "!" _?) e:searchExpr {
      RETURN(h.MakeLogicalNot(e))
    }
  / !("-") s:searchPred { RETURN(s) }
  / "(" _? expr:searchExpr _? ")" { RETURN(expr) }

searchPred
  = "*" _? fieldComparator:equalityToken _? v:searchValue {
      RETURN(h.MakeCompareAny(fieldComparator, false, v))
    }
  / "**" _? fieldComparator:equalityToken _? v:searchValue {
      RETURN(h.MakeCompareAny(fieldComparator, true, v))
    }
  / "*" {
      RETURN(h.MakeBooleanLiteral(true))
    }
  / f:fieldExpr _? fieldComparator:equalityToken _? v:searchValue {
      RETURN(h.MakeCompareField(fieldComparator, f, v))
    }
  / v:searchValue _? inToken _? "*" {
      RETURN(h.MakeCompareAny("in", false, v))
    }
  / v:searchValue _? inToken _? f:fieldReference {
      RETURN(h.MakeCompareField("in", f, v))
    }
  / v:searchValue {
      INIT_ASSIGN_VAR(ss, h.MakeSearchString(v))
      IF(h.GetValueType(v) == "string") {
        RETURN(ss)
      }
      ss = h.MakeSearchString(h.MakeTypedValue("string", TEXT))
      RETURN(h.MakeOrChain(ss, ARRAY(h.MakeCompareAny("eql", true, v), h.MakeCompareAny("in", true, v))))
    }

searchValue
  = v:quotedString {
      RETURN(h.MakeTypedValue("string", v))
    }
  / v:reString {
      RETURN(h.MakeTypedValue("regexp", v))
    }
  / v:port {
      RETURN(h.MakeTypedValue("port", v))
  }
  / v:ip6subnet {
      RETURN(h.MakeTypedValue("subnet", v))
    }
  / v:ip6addr {
      RETURN(h.MakeTypedValue("addr", v))
    }
  / v:subnet {
      RETURN(h.MakeTypedValue("subnet", v))
    }
  / v:addr {
      RETURN(h.MakeTypedValue("addr", v))
    }
  / v:sdouble {
      RETURN(h.MakeTypedValue("double", v))
    }
  / v:sinteger !boomWord {
      RETURN(h.MakeTypedValue("int", v))
    }
  / !(searchKeywords _) v:booleanLiteral { RETURN(v) }
  / !(searchKeywords _) v:unsetLiteral { RETURN(v) }
  / !(searchKeywords _) v:boomWord {
      IF(reglob.IsGlobby(ASSERT_STRING(v)) || ASSERT_STRING(v) == "*") {
         INIT_ASSIGN_VAR(re, reglob.Reglob(ASSERT_STRING(v)))
         RETURN(h.MakeTypedValue("regexp", re))
      }
      RETURN(h.MakeTypedValue("string", v))
    }

searchKeywords
  = andToken
  / orToken
  / inToken

booleanLiteral
  = "true"           { RETURN(h.MakeTypedValue("bool", "true")) }
  / "false"          { RETURN(h.MakeTypedValue("bool", "false")) }

unsetLiteral
  = "nil"           { RETURN(h.MakeTypedValue("unset", "")) }

procList
  = first:procChain rest:parallelChain* {
      INIT_ASSIGN_VAR(fp, h.MakeSequentialProc(first))
      IF(ISNOTNULL(rest)) {
        RETURN(h.MakeParallelProc(PREPEND(fp, rest)))
      } else {
        RETURN(fp)
      }
    }

parallelChain
  = _? ";" _? ch:procChain { RETURN(h.MakeSequentialProc(ch)) }

proc
  = simpleProc
  / reducerProc
  / "(" _? proc:procList _? ")" {
      RETURN(proc)
    }

groupBy
  = "by"i _ list:fieldExprList { RETURN(list) }

everyDur
  = "every"i _ dur:duration { RETURN(dur) }

equalityToken
  = "=" { RETURN("eql") }
  / "!=" { RETURN("neql") }
  / "<=" { RETURN("lte") }
  / ">=" { RETURN("gte") }
  / "<" { RETURN("lt") }
  / ">" { RETURN("gt") }

types
  = "bool"
  / "int"
  / "count"
  / "double"
  / "string"
  / "addr"
  / "subnet"
  / "port"

dash = "-" / "\u2014" / "\u2013" / "to"&(_)

andToken = "and"
orToken = "or"
inToken = "in"
notToken = "not"

fieldName = fieldNameStart fieldNameRest* { RETURN(TEXT) }

fieldNameStart = [A-Za-z_$]
fieldNameRest = fieldNameStart / [0-9]

fieldReference
 = base:fieldName derefs:(
       "." field:fieldName    { RETURN(h.MakeFieldCall("RecordFieldRead", NULL, field)) }
     / "[" index:sinteger "]" { RETURN(h.MakeFieldCall("Index", NULL, index)) }
   )* {
     RETURN(h.ChainFieldCalls(base, derefs))
   }

fieldExpr
  = op:fieldOp _? "(" _? field:fieldReference _? ")" {
      RETURN(h.MakeFieldCall(op, field, nil))
    }
  / fieldReference

fieldOp
  = "len"i { RETURN("Len") }

fieldExprList
  = first:fieldExpr rest:(_? "," _? fieldExpr)* {
      INIT_ASSIGN_VAR(result, ARRAY(first))

      FOREACH(ASSERT_ARRAY(rest), r) {
        APPEND(result, ASSERT_ARRAY(r)[3])
      }

      RETURN(result)
  }

fieldRefDotOnly
  = base:fieldName refs:("." field:fieldName { RETURN(h.MakeFieldCall("RecordFieldRead", NULL, field)) } )* {
    RETURN(h.ChainFieldCalls(base, refs))
  }

fieldRefDotOnlyList
  = first:fieldRefDotOnly rest:(_? "," _? ref:fieldRefDotOnly { RETURN(ref) })* {
  INIT_ASSIGN_VAR(result, ARRAY(first))
  FOREACH(ASSERT_ARRAY(rest), r) {
    APPEND(result, r)
  }
  RETURN(result)
  }

fieldNameList
  = first:fieldName rest:(_? "," _? fieldName)* {
      INIT_ASSIGN_VAR(result, ARRAY(first))
      FOREACH(ASSERT_ARRAY(rest), r) {
        APPEND(result, ASSERT_ARRAY(r)[3])
      }
      RETURN(result)
  }

countOp
  = "count"i { RETURN("Count") }

fieldReducerOp
  = "sum"i  { RETURN("Sum") }
  / "avg"i  { RETURN("Avg") }
  / "stdev"i { RETURN("Stdev") }
  / "sd"i   { RETURN("Stdev") }
  / "var"i  { RETURN("Var") }
  / "entropy"i { RETURN("Entropy") }
  / "min"i  { RETURN("Min") }
  / "max"i  { RETURN("Max") }
  / "first"i  { RETURN("First") }
  / "last"i  { RETURN("Last") }
  / "countdistinct"i { RETURN("CountDistinct") }

paddedFieldName = _? field:fieldName _? { RETURN(field) }

countReducer
  = op:countOp _? "(" field:paddedFieldName?  _? ")" {
    RETURN(h.MakeReducer(op, "count", field))
  }

fieldReducer
  = op:fieldReducerOp _? "(" _? field:fieldName  _? ")" {
    RETURN(h.MakeReducer(op, h.ToLowerCase(op), field))
  }

reducerProc
  = every:(everyDur _)? reducers:reducerList keys:(_ groupBy)? limit:procLimitArg? {
    if ISNOTNULL(h.OR(keys, every)) {
      if ISNOTNULL(keys) {
        keys = ASSERT_ARRAY(keys)[1]
      } else {
        keys = ARRAY()
      }

      if ISNOTNULL(every) {
        every = ASSERT_ARRAY(every)[0]
      }

      RETURN(h.MakeGroupByProc(every, limit, keys, reducers))
    }

    RETURN(h.MakeReducerProc(reducers))
  }

asClause
  = "as"i _ v:fieldName { RETURN(v) }

reducerExpr
  = field:fieldName _? "=" _? f:reducer {
    RETURN(h.OverrideReducerVar(f, field))
  }
  / f:reducer _ field:asClause {
    RETURN(h.OverrideReducerVar(f, field))
  }
  / reducer

reducer
  = countReducer
  / fieldReducer

reducerList
  = first:reducerExpr rest:(_? "," _? reducerExpr)* {
      INIT_ASSIGN_VAR(result, ARRAY(first))
      FOREACH(ASSERT_ARRAY(rest), r) {
        APPEND(result, ASSERT_ARRAY(r)[3])
      }
      RETURN(result)
    }

simpleProc
  = sort
  / top
  / cut
  / head
  / tail
  / filter
  / uniq

sort
  = "sort"i rev:(_ "-r")? limit:procLimitArg?  _? !"-r" list:(fieldExprList)? {
    INIT_ASSIGN_VAR(sortdir, 1)
    IF(ISNOTNULL(rev)) { sortdir = -1 }
    RETURN(h.MakeSortProc(list, sortdir, limit))
  }
  / "sort"i limit:procLimitArg? rev:(_ "-r")? _? list:(fieldExprList)? {
    INIT_ASSIGN_VAR(sortdir, 1)
    IF(ISNOTNULL(rev)) { sortdir = -1 }
    RETURN(h.MakeSortProc(list, sortdir, limit))
  }

top
  = "top"i limit:procLimitArg? flush:(_ "-flush")? _? list:(fieldExprList)? {
    RETURN(h.MakeTopProc(list, limit, flush))
  }

procLimitArg
  = _ "-limit" _ limit:integer { RETURN(limit) }

cut
  = "cut"i _ list:fieldRefDotOnlyList { RETURN(h.MakeCutProc(list)) }
head
  = "head"i _ count:integer { RETURN(h.MakeHeadProc(count)) }
  / "head"i { RETURN(h.MakeHeadProc(1)) }
tail
  = "tail"i _ count:integer { RETURN(h.MakeTailProc(count)) }
  / "tail"i { RETURN(h.MakeTailProc(1)) }

filter
  = "filter"i _ expr:searchExpr {
      RETURN(h.MakeFilterProc(expr))
    }
uniq
  = "uniq"i _ "-c" {
      RETURN(h.MakeUniqProc(true))
    }
  / "uniq"i {
      RETURN(h.MakeUniqProc(false))
    }

duration
  = seconds
  / minutes
  / hours
  / hours _ "and" _ minutes
  / days
  / weeks

sec_abbrev
  = "seconds"
  / "second"
  / "secs"
  / "sec"
  / "s"

min_abbrev
  = "minutes"
  / "minute"
  / "mins"
  / "min"
  / "m"

hour_abbrev
  = "hours"
  / "hrs"
  / "hr"
  / "h"
  / "hour"

day_abbrev = "days"/"day"/"d"
week_abbrev = "weeks"/"week"/"wks"/"wk"/"w"

seconds
  = "second" { RETURN(h.MakeDuration(1)) }
  / num:number _? sec_abbrev { RETURN(h.MakeDuration(num)) }

minutes
  = "minute" { RETURN(h.MakeDuration(60)) }
  / num:number _? min_abbrev { RETURN(h.MakeDuration(ASSERT_INT(num)*60)) }

hours
  = "hour" { RETURN(h.MakeDuration(3600)) }
  / num:number _? hour_abbrev { RETURN(h.MakeDuration(ASSERT_INT(num)*3600)) }

days
  = "day" { RETURN(h.MakeDuration(3600*24)) }
  / num:number _? day_abbrev { RETURN(h.MakeDuration(ASSERT_INT(num)*3600*24)) }

weeks
  = num:number _? week_abbrev { RETURN(h.MakeDuration(ASSERT_INT(num)*3600*24*7)) }

number = integer


//XXX what about mac addrs?
addr
  = a:(integer "." integer "." integer "." integer) { RETURN(TEXT) }

port
  = ":" v:sinteger { RETURN(v) }

// this matches a superset of legal syntax for ip6 addresses but the compiler
// will catch any errors when translating the filter
ip6addr
  = a:(h_prepend)+ b:ip6tail {
      RETURN(h.JoinChars(a) + ASSERT_STRING(b))
    }
  / a:h16 b:(h_append)* "::" d:(h_prepend)* e:ip6tail {
      RETURN(ASSERT_STRING(a) + h.JoinChars(b) + "::" + h.JoinChars(d) + ASSERT_STRING(e))
    }
  / "::" a:(h_prepend)* b:ip6tail {
      RETURN("::" + h.JoinChars(a) + ASSERT_STRING(b))
    }
  / a:h16 b:(h_append)* "::" {
      RETURN(ASSERT_STRING(a) + h.JoinChars(b) + "::")
    }
  / "::" {
      RETURN("::")
    }

ip6tail
  = addr
  / h16

h_append = ":" v:h16 { RETURN(":" + ASSERT_STRING(v)) }
h_prepend = v:h16 ":" { RETURN(ASSERT_STRING(v) + ":") }

sub_addr
  = addr
  / a:(integer "." integer "." integer ) { RETURN(TEXT + ".0") }
  / a:(integer "." integer ) { RETURN(TEXT + ".0.0") }
  / a:integer { RETURN(TEXT + ".0.0.0") }

subnet
  = a:sub_addr '/' m:integer {
      RETURN(ASSERT_STRING(a) + "/" + TOSTRING(m));
    }

ip6subnet
  = a:ip6addr '/' m:integer {
      RETURN(ASSERT_STRING(a) + "/" + ASSERT_STRING(m));
    }

integer
  = s:sinteger {
    RETURN(h.ParseInt(s))
  }

sinteger
  = chars:[0-9]+ {
    RETURN(TEXT)
  }

double
  = s:sdouble {
      RETURN(h.ParseFloat(s))
  }

sdouble
  = doubleInteger+ "." doubleDigit+ exponentPart? {
      RETURN(TEXT)
    }
  / "." doubleDigit+ exponentPart? {
      RETURN(TEXT)
    }

doubleInteger
  = "0"
  / [1-9] [0-9]*

doubleDigit = [0-9]

signedInteger = [+-]? doubleDigit+

exponentPart = "e"i signedInteger

h16 = chars:hexdigit+ { RETURN(TEXT) }

hexdigit = [0-9a-fA-F]

boomWord "boomWord" = chars:boomWordPart+ { RETURN(h.JoinChars(chars)) }

boomWordPart
  = "\\" s:escapeSequence  { RETURN(s) }
  / !([\x00-\x1F\x5C(),!><=DQUOTE|SQUOTE;] / ws) . { RETURN(TEXT) }

quotedString
  = '"' v:doubleQuotedChar* '"' { RETURN(h.JoinChars(v)) }
  / "'" v:singleQuotedChar* "'" { RETURN(h.JoinChars(v)) }

doubleQuotedChar
  = !('"' / escapedChar) . { RETURN(TEXT) }
  / "\\" s:escapeSequence { RETURN(s) }

singleQuotedChar
  = !("'" / escapedChar) . { RETURN(TEXT) }
  / "\\" s:escapeSequence { RETURN(s) }

escapeSequence
  = "x" hexdigit hexdigit { RETURN("\\" + TEXT) }
  / singleCharEscape
  / unicodeEscape

singleCharEscape
  = "'"
  / '"'
  / "\\"
  / "b" { RETURN("\b") }
  / "f" { RETURN("\f") }
  / "n" { RETURN("\n") }
  / "r" { RETURN("\r") }
  / "t" { RETURN("\t") }
  / "v" { RETURN("\v") }

unicodeEscape
  = "u" hexdigit hexdigit hexdigit hexdigit

reString
  = '/' v:reBody '/' { RETURN(v) }

reBody
  = ([^/\\]/"\\/")+ { RETURN(TEXT) }

escapedChar
  = [\x00-\x1f\\]

ws
  = "\t"
  / "\v"
  / "\f"
  / " "
  / "\u00A0"
  / "\uFEFF"

_ "whitespace" = ws+

EOF = !.
